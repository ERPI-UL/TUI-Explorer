{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5956d79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exports écrits dans: C:\\Users\\rodrig296u\\Documents\\Prog\\Jupyter\\exports_stats\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, unicodedata, re\n",
    "from datetime import date\n",
    "\n",
    "# Fichiers\n",
    "DATA = Path(\"Etat_De_Lart.xlsx\")   \n",
    "EXPORTS = Path(\"exports_stats\"); EXPORTS.mkdir(exist_ok=True)\n",
    "\n",
    "# Chargement + renommage colonnes pour avoir des nom + normés\n",
    "df = pd.read_excel(DATA).rename(columns={\n",
    "    \"Nom du système\": \"system_name\",\n",
    "    \"Input Modalities\": \"input_modality\",\n",
    "    \"Ouput Modalities\": \"output_modality\",\n",
    "    \"Delivery Technology\": \"delivery_tech\",\n",
    "    \"Reception technology\": \"reception_tech\",\n",
    "    \"Object\": \"object_type\",\n",
    "    \"Date\": \"date\",\n",
    "    \"Titre de l'article\": \"paper_title\",\n",
    "})\n",
    "\n",
    "# Split générique entre nos critères , ;, /, +, \"et\", \"and\"\n",
    "SPLIT_REGEX = r\"[;,/|＋\\+]|(?:\\s+et\\s+)|(?:\\s+and\\s+)\"\n",
    "\n",
    "# on protege Microcontroler ect du regex\n",
    "PROTECTED_PATTERNS_BY_COL = {\n",
    "    \"reception_tech\": [\n",
    "        (\n",
    "            re.compile(\n",
    "                r\"\\bmicrocontrollers?\\s*,?\\s*sensors?\\s*,?\\s*(?:and|et|&)\\s+actuators?\\b\",\n",
    "                flags=re.IGNORECASE\n",
    "            ),\n",
    "            \"Microcontrollers, Sensors, and Actuators\"\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "\n",
    "def tokenize(val, col_name=None):\n",
    "    if pd.isna(val):\n",
    "        return []\n",
    "    s = unicodedata.normalize(\"NFKC\", str(val)).strip()\n",
    "    placeholders = {}\n",
    "    if col_name in PROTECTED_PATTERNS_BY_COL:\n",
    "        for idx, (pat, canonical) in enumerate(PROTECTED_PATTERNS_BY_COL[col_name]):\n",
    "            ph = f\"__PROT{idx}__\"\n",
    "            s, n = pat.subn(ph, s)\n",
    "            if n > 0:\n",
    "                placeholders[ph] = canonical\n",
    "    parts = re.split(SPLIT_REGEX, s, flags=re.IGNORECASE)\n",
    "    out = []\n",
    "    for p in parts:\n",
    "        t = norm(p)\n",
    "        if isinstance(t, str) and t:\n",
    "            t = t.strip(' \"“”‘’[]()')\n",
    "            if not t:\n",
    "                continue\n",
    "            out.append(placeholders.get(t, t))\n",
    "    return out\n",
    "\n",
    "def explode_and_canon(df, col_name, token_col):\n",
    "    rows = []\n",
    "    for _, r in df[[\"system_name\", col_name]].iterrows():\n",
    "        for t in tokenize(r[col_name], col_name):\n",
    "            ct = CANON_FUN[col_name](t) if 'CANON_FUN' in globals() and col_name in CANON_FUN else t\n",
    "            if ct:\n",
    "                rows.append({\"system_name\": r[\"system_name\"], token_col: ct})\n",
    "    out = pd.DataFrame(rows)\n",
    "    if not out.empty:\n",
    "        out = out.drop_duplicates([\"system_name\", token_col])\n",
    "    return out\n",
    "\n",
    "# Tables de tokens pour avoir accès plus faciement a chaque critères \n",
    "input_tok     = explode_and_canon(df, \"input_modality\", \"input_token\")\n",
    "delivery_tok  = explode_and_canon(df, \"delivery_tech\", \"delivery_token\")\n",
    "output_tok    = explode_and_canon(df, \"output_modality\", \"output_token\")\n",
    "reception_tok = explode_and_canon(df, \"reception_tech\", \"reception_token\")\n",
    "object_tok    = explode_and_canon(df, \"object_type\", \"object_token\")\n",
    "\n",
    "#pour les libellés des axes \n",
    "AXIS_Y = {\n",
    "    \"input_modality\":  \"Input modalities\",\n",
    "    \"object_type\":     \"Object Characteristics\",\n",
    "    \"reception_tech\":  \"Reception Technologies\",\n",
    "    \"delivery_tech\":   \"Delivery Technologies\",\n",
    "    \"output_modality\": \"Output Modalities\",\n",
    "}\n",
    "X_LABEL_COUNT   = \"Number of systems\"\n",
    "X_LABEL_PERCENT = \"Percent of systems (%)\"\n",
    "\n",
    "# trace un histograme \n",
    "def _barh(series, ylabel, xlabel, out_name, xlim=None, step=None):\n",
    "    if series is None or series.empty:\n",
    "        fig, ax = plt.subplots(figsize=(4,3)); ax.axis(\"off\")\n",
    "        plt.savefig(EXPORTS / out_name, dpi=200, bbox_inches=\"tight\"); plt.close(fig); return\n",
    "    s = series.sort_values()  \n",
    "    labels = [str(i) for i in s.index]\n",
    "    max_lbl = max((len(x) for x in labels), default=8)\n",
    "    fig_w = max(7.5, 7.0 + 0.06 * max_lbl)\n",
    "    fig_h = max(3.5, 0.35 * len(labels) + 1.2)\n",
    "    fig, ax = plt.subplots(figsize=(fig_w, fig_h))\n",
    "    s.plot(kind=\"barh\", ax=ax)\n",
    "    ax.set_ylabel(ylabel); ax.set_xlabel(xlabel)\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(0, xlim)\n",
    "        if step: ax.set_xticks(range(0, xlim + 1, step))\n",
    "    left = min(0.5, 0.12 + 0.012 * max_lbl)\n",
    "    fig.subplots_adjust(left=left, right=0.98, top=0.98, bottom=0.14)\n",
    "    plt.savefig(EXPORTS / out_name, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "\n",
    "# Pour chaque critères ressort son total en cout et en %\n",
    "def plot_counts_and_percents(dims):\n",
    "    counts = []\n",
    "    xmax = 0\n",
    "    for d in dims:\n",
    "        s = d[\"df\"][d[\"col\"]].value_counts() if d[\"df\"] is not None and not d[\"df\"].empty else pd.Series(dtype=int)\n",
    "        counts.append((d, s))\n",
    "        if not s.empty:\n",
    "            xmax = max(xmax, int(s.max()))\n",
    "    common_x = int(np.ceil(xmax / 50.0) * 50) if xmax > 0 else 50\n",
    "\n",
    "    for d, s in counts:\n",
    "        _barh(s, d[\"y\"], \"Number of systems\", f\"{d['stub']}_tokens_count.png\", xlim=common_x, step=50)\n",
    "        if not s.empty:\n",
    "            p = (s / s.sum() * 100).round(1)\n",
    "        else:\n",
    "            p = s\n",
    "        _barh(p, d[\"y\"], \"Percent of systems (%)\", f\"{d['stub']}_tokens_percent.png\", xlim=100, step=10)\n",
    "\n",
    "\n",
    "# def pour les heatmaps plus vraiment utile \n",
    "def plot_heatmap(dfA, colA, dfB, colB, xlabel, ylabel, out_name, annotate=False):\n",
    "    if dfA is None or dfA.empty or dfB is None or dfB.empty:\n",
    "        fig, ax = plt.subplots(figsize=(4,3)); ax.axis(\"off\")\n",
    "        plt.savefig(EXPORTS / out_name, dpi=200, bbox_inches=\"tight\"); plt.close(fig); return\n",
    "    pairs = dfA[[\"system_name\", colA]].merge(\n",
    "        dfB[[\"system_name\", colB]], on=\"system_name\", how=\"inner\")\n",
    "    if pairs.empty:\n",
    "        fig, ax = plt.subplots(figsize=(4,3)); ax.axis(\"off\")\n",
    "        plt.savefig(EXPORTS / out_name, dpi=200, bbox_inches=\"tight\"); plt.close(fig); return\n",
    "    pivot = pd.crosstab(pairs[colA], pairs[colB])\n",
    "    n_rows, n_cols = pivot.shape\n",
    "    cell_w, cell_h = 1.2, 0.9\n",
    "    fig_w = max(6.5, cell_w * n_cols + 2.5); fig_h = max(4.5, cell_h * n_rows + 2.5)\n",
    "    fig, ax = plt.subplots(figsize=(fig_w, fig_h))\n",
    "    im = ax.imshow(pivot.values, aspect=\"auto\", interpolation=\"nearest\")\n",
    "    ax.set_xticks(range(n_cols)); ax.set_yticks(range(n_rows))\n",
    "    ax.set_xticklabels(pivot.columns, rotation=30, ha=\"right\")\n",
    "    ax.set_yticklabels(pivot.index)\n",
    "    ax.set_xlabel(xlabel); ax.set_ylabel(ylabel); ax.tick_params(labelsize=10)\n",
    "    if annotate:\n",
    "        for i in range(n_rows):\n",
    "            for j in range(n_cols):\n",
    "                ax.text(j, i, str(int(pivot.values[i, j])), ha=\"center\", va=\"center\", fontsize=9)\n",
    "    max_x = max((len(str(x)) for x in pivot.columns), default=5)\n",
    "    max_y = max((len(str(y)) for y in pivot.index), default=5)\n",
    "    bottom = min(0.6, 0.16 + 0.010 * max_x); left = min(0.6, 0.12 + 0.012 * max_y)\n",
    "    fig.subplots_adjust(left=left, right=0.98, top=0.98, bottom=bottom)\n",
    "    fig.colorbar(im, ax=ax, fraction=0.035, pad=0.04)\n",
    "    plt.savefig(EXPORTS / out_name, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    pivot.to_csv(EXPORTS / (Path(out_name).stem + \".csv\"))\n",
    "\n",
    "\n",
    "dims = [\n",
    "    {\"stub\":\"input\",          \"y\":\"Input modalities\",      \"df\": input_tok,     \"col\":\"input_token\"},\n",
    "    {\"stub\":\"delivery_tech\",  \"y\":\"Delivery Technologies\", \"df\": delivery_tok,  \"col\":\"delivery_token\"},\n",
    "    {\"stub\":\"output_modality\",\"y\":\"Output Modalities\",     \"df\": output_tok,    \"col\":\"output_token\"},\n",
    "    {\"stub\":\"reception_tech\", \"y\":\"Reception Technologies\",\"df\": reception_tok, \"col\":\"reception_token\"},\n",
    "    {\"stub\":\"object_type\",    \"y\":\"Object Characteristics\",\"df\": object_tok,    \"col\":\"object_token\"},\n",
    "]\n",
    "plot_counts_and_percents(dims)\n",
    "\n",
    "# Heatmaps \n",
    "plot_heatmap(input_tok, \"input_token\", reception_tok, \"reception_token\",\n",
    "             xlabel=\"Reception Technologies\", ylabel=\"Input modalities\",\n",
    "             out_name=\"input_tokens_x_reception_tokens.png\", annotate=False)\n",
    "\n",
    "plot_heatmap(input_tok, \"input_token\", delivery_tok, \"delivery_token\",\n",
    "             xlabel=\"Delivery Technologies\", ylabel=\"Input modalities\",\n",
    "             out_name=\"input_tokens_x_delivery_tokens.png\", annotate=False)\n",
    "\n",
    "\n",
    "print(\"c'est bien exporté ici\", EXPORTS.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fef18848-3a20-4f73-8bf7-d2b0e24ea3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "\n",
    "TOP_N = 5  \n",
    "\n",
    "def plot_trends_lines(pivot: pd.DataFrame, outfile_png: str, top_n: int = TOP_N, y_step: int = 5):\n",
    "    if pivot is None or pivot.empty:\n",
    "        fig, ax = plt.subplots(figsize=(6, 3)); ax.axis(\"off\")\n",
    "        plt.savefig(EXPORTS / outfile_png, dpi=200, bbox_inches=\"tight\"); plt.close(fig); return\n",
    "\n",
    "    totals = pivot.sum(axis=0).sort_values(ascending=False)\n",
    "    cols = totals.index[:min(top_n, len(totals))].tolist()\n",
    "    data = pivot[cols].copy()\n",
    "\n",
    "    years = data.index.tolist()\n",
    "    x = np.arange(len(years))\n",
    "    fig_w = max(10, 0.6 * len(years))\n",
    "    fig, ax = plt.subplots(figsize=(fig_w, 6))\n",
    "\n",
    "    for c in cols:\n",
    "        ax.plot(x, data[c].values, label=c, linewidth=2)\n",
    "\n",
    "    # Axes\n",
    "    ax.set_xlabel(\"Year\")\n",
    "    ax.set_ylabel(\"Number of systems\")\n",
    "    ax.set_xlim(-0.2, len(years) - 0.8)\n",
    "\n",
    "    step_x = 1 if len(years) <= 12 else 2\n",
    "    ax.set_xticks(x[::step_x])\n",
    "    ax.set_xticklabels([str(y) for y in years][::step_x])\n",
    "\n",
    "    ymax_data = float(np.nanmax(data.values)) if data.size else 0.0\n",
    "    ymax = int(np.ceil(ymax_data / y_step) * y_step) or y_step\n",
    "    ax.set_ylim(0, ymax)\n",
    "    ax.set_yticks(np.arange(0, ymax + 1, y_step))\n",
    "    ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%d'))\n",
    "\n",
    "    ax.legend(loc=\"center left\", bbox_to_anchor=(1.02, 0.5), borderaxespad=0.)\n",
    "    fig.subplots_adjust(left=0.10, right=0.80, top=0.98, bottom=0.16)\n",
    "    # export\n",
    "    plt.savefig(EXPORTS / outfile_png, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "# Génération des courbes pour chaque critère plus très utile\n",
    "for name, dft, tok_col in [\n",
    "    (\"input_modality\",  input_tok,     \"input_token\"),\n",
    "    (\"object_type\",     object_tok,    \"object_token\"),\n",
    "    (\"reception_tech\",  reception_tok, \"reception_token\"),\n",
    "    (\"delivery_tech\",   delivery_tok,  \"delivery_token\"),\n",
    "    (\"output_modality\", output_tok,    \"output_token\"),\n",
    "]:\n",
    "    pivot = trends_by_year(dft, tok_col, systems_year, YEARS)\n",
    "    plot_trends_lines(pivot, f\"trend_{name}_lines.png\", top_n=TOP_N, y_step=5)\n",
    "\n",
    "# Time trend des systems par années\n",
    "\n",
    "def plot_total_systems_per_year(systems_year_df, years, outfile_png=\"trend_total_systems_per_year.png\", y_step=5):\n",
    "    if systems_year_df is None or systems_year_df.empty:\n",
    "        fig, ax = plt.subplots(figsize=(6, 3)); ax.axis(\"off\")\n",
    "        # export \n",
    "        plt.savefig(EXPORTS / outfile_png, dpi=200, bbox_inches=\"tight\"); plt.close(fig); return\n",
    "\n",
    "    ts = (systems_year_df.groupby(\"year\")[\"system_name\"]\n",
    "          .nunique()\n",
    "          .reindex(years, fill_value=0))\n",
    "    # export CSV\n",
    "    ts.rename(\"count\").to_csv(EXPORTS / \"trend_total_systems_per_year.csv\", header=True)\n",
    "\n",
    "    x = np.arange(len(years))\n",
    "    fig_w = max(10, 0.6 * len(years))\n",
    "    fig, ax = plt.subplots(figsize=(fig_w, 6))\n",
    "\n",
    "    ax.plot(x, ts.values, linewidth=2, label=\"Total systems\")\n",
    "\n",
    "    ax.set_xlabel(\"Year\")\n",
    "    ax.set_ylabel(\"Number of systems\")\n",
    "    ax.set_xlim(-0.2, len(years) - 0.8)\n",
    "\n",
    "    step_x = 1 if len(years) <= 12 else 2\n",
    "    ax.set_xticks(x[::step_x])\n",
    "    ax.set_xticklabels([str(y) for y in years][::step_x])\n",
    "\n",
    "    ymax_data = float(np.nanmax(ts.values)) if ts.size else 0.0\n",
    "    ymax = int(np.ceil(ymax_data / y_step) * y_step) or y_step\n",
    "    ax.set_ylim(0, ymax)\n",
    "    ax.set_yticks(np.arange(0, ymax + 1, y_step))\n",
    "    ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%d'))\n",
    "\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    fig.subplots_adjust(left=0.10, right=0.98, top=0.98, bottom=0.16)\n",
    "    # export CSV\n",
    "    plt.savefig(EXPORTS / outfile_png, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "plot_total_systems_per_year(systems_year, YEARS, outfile_png=\"trend_total_systems_per_year.png\", y_step=5)\n",
    "\n",
    "print(\"c'est bien exporté ici\", EXPORTS.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b54cb733-fd86-432f-81ca-2cd2c9b37fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sankey (Input -> Object -> Reception -> Delivery -> Output)\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    def build_sankey_from_layers(layers, html_path):\n",
    "        labels=[]; node_index={}\n",
    "        for i, (_, df_layer, col) in enumerate(layers):\n",
    "            if df_layer is None or df_layer.empty: continue\n",
    "            for v in sorted(df_layer[col].dropna().unique().tolist()):\n",
    "                node_index[(i, v)] = len(labels); labels.append(str(v))\n",
    "        sources, targets, values = [], [], []\n",
    "        for i in range(len(layers)-1):\n",
    "            _, df_a, col_a = layers[i]; _, df_b, col_b = layers[i+1]\n",
    "            if df_a is None or df_b is None or df_a.empty or df_b.empty: continue\n",
    "            a = df_a[[\"system_name\", col_a]].drop_duplicates()\n",
    "            b = df_b[[\"system_name\", col_b]].drop_duplicates()\n",
    "            m = a.merge(b, on=\"system_name\", how=\"inner\")\n",
    "            if m.empty: continue\n",
    "            ct = m.groupby([col_a, col_b]).size().reset_index(name=\"value\")\n",
    "            for va, vb, vv in zip(ct[col_a], ct[col_b], ct[\"value\"]):\n",
    "                if (i, va) in node_index and (i+1, vb) in node_index:\n",
    "                    sources.append(node_index[(i, va)]); targets.append(node_index[(i+1, vb)]); values.append(int(vv))\n",
    "        if not values: return None\n",
    "        fig = go.Figure(data=[go.Sankey(node=dict(label=labels, pad=10, thickness=15),\n",
    "                                        link=dict(source=sources, target=targets, value=values))])\n",
    "        fig.write_html(html_path); return html_path\n",
    "    build_sankey_from_layers(\n",
    "        layers=[(\"Input\", input_tok, \"input_token\"),\n",
    "                (\"Object\", object_tok, \"object_token\"),\n",
    "                (\"Reception\", reception_tok, \"reception_token\"),\n",
    "                (\"Delivery\", delivery_tok, \"delivery_token\"),\n",
    "                (\"Output\", output_tok, \"output_token\")],\n",
    "        html_path=str(EXPORTS / \"sankey_tokens_input_object_reception_delivery_output.html\"),\n",
    "    )\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"c'est bien exporté ici\", EXPORTS.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
